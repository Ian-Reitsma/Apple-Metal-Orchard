[orchard][flashpatch] FlashAttention monkeypatch NOT ENABLED (USE_FLASH_ATTN!=1)
MPS available: True MPS built: True
[DEBUG][BASELINE] Output shape: torch.Size([2, 2048, 768]), dtype: torch.bfloat16
[DEBUG][BASELINE] Output shape: torch.Size([2, 2048, 768]), dtype: torch.bfloat16
[DEBUG][BASELINE] Output shape: torch.Size([2, 2048, 768]), dtype: torch.bfloat16
[DEBUG][BASELINE] Output shape: torch.Size([2, 2048, 768]), dtype: torch.bfloat16
[DEBUG][BASELINE] Output shape: torch.Size([2, 2048, 768]), dtype: torch.bfloat16
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_bench_v0.8.py", line 144, in <module>
    model(ids, labels=ids)
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1189, in forward
    transformer_outputs = self.transformer(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 917, in forward
    outputs = block(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/transformers/modeling_layers.py", line 83, in __call__
    return super().__call__(*args, **kwargs)
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 404, in forward
    attn_output, self_attn_weights = self.attn(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 336, in forward
    attn_output, attn_weights = attention_interface(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/transformers/integrations/sdpa_attention.py", line 66, in sdpa_attention_forward
    attn_output = torch.nn.functional.scaled_dot_product_attention(
RuntimeError: MPS backend out of memory (MPS allocated: 8.40 GB, other allocations: 396.69 MB, max allowed: 9.07 GB). Tried to allocate 384.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).
