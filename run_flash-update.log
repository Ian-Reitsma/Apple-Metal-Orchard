>> QUICK-CHECK mode: bs=4 seq=256 steps=40 (≈15-min run)
[orchard][flashpatch] FlashAttention monkeypatch ENABLED (GPT2Attention.forward, log=True, detail=False)
MPS available: True MPS built: True
[orchard] FlashAttention loaded (SHA 2e7c3ee4…)
[orchard][flashpatch] --- FlashAttention Patch Context ---
  PATCH_ENABLED: True
  FLASHATTN_LOG_KERNEL: True
  FLASHATTN_LOG_DETAIL: False
  torch version: 2.7.1
  Model config (first layer): GPT2Config {
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "torch_dtype": "float32",
  "transformers_version": "4.53.0",
  "use_cache": true,
  "vocab_size": 50257
}

  Example Q shape: torch.Size([4, 12, 256, 64]), dtype: torch.bfloat16, device: mps:0
  ENV: USE_FLASH_ATTN=1, PYTHONHASHSEED=None
-------------------------------------------------------------
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 1 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 2 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 3 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 4 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 5 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 6 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 7 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 8 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 9 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 10 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 11 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 12 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 13 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 14 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 15 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 16 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 17 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 18 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 19 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 20 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 21 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 22 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 23 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 24 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 25 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 26 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 27 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 28 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 29 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 30 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 31 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 32 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 33 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 34 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 35 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 36 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][noflash_bs1_seq4096] step 1/40 ( 2.5%)  wall=   1.9s  tps≈  552.0
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 37 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 38 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 39 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 40 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 41 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 42 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 43 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 44 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 45 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 46 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 47 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 48 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 49 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 50 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 51 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 52 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 53 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 54 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 55 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 56 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 57 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 58 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 59 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 60 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 61 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 62 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 63 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 64 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 65 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 66 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 67 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 68 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 69 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 70 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 71 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 72 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 73 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 74 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 75 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 76 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 77 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 78 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 79 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 80 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 81 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 82 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 83 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 84 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 85 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 86 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 87 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 88 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 89 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 90 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 91 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 92 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 93 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 94 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 95 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 96 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 97 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 98 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 99 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 100 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 101 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 102 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 103 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 104 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 105 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 106 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 107 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 108 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 109 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 110 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 111 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 112 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 113 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 114 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 115 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 116 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 117 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 118 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 119 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 120 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 121 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 122 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 123 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 124 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 125 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 126 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 127 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 128 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 129 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 130 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 131 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 132 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][noflash_bs1_seq4096] step 9/40 (22.5%)  wall=  12.9s  tps≈  717.1
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 133 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 134 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 135 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 136 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 137 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 138 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 139 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 140 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 141 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 142 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 143 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 144 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 145 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 146 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 147 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 148 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 149 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 150 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 151 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 152 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 153 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 154 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 155 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 156 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 157 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 158 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 159 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 160 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 161 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 162 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 163 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 164 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 165 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 166 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 167 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 168 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 169 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 170 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 171 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 172 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 173 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 174 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 175 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 176 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 177 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 178 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 179 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 180 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 181 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 182 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 183 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 184 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 185 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 186 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 187 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 188 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 189 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 190 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 191 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 192 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 193 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 194 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 195 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 196 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 197 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 198 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 199 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 200 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 201 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 202 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 203 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 204 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 205 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 206 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 207 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 208 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 209 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 210 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 211 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 212 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 213 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 214 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 215 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 216 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 217 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 218 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 219 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 220 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 221 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 222 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 223 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 224 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 225 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 226 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 227 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 228 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][noflash_bs1_seq4096] step 17/40 (42.5%)  wall=  24.1s  tps≈  723.8
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 229 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 230 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 231 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 232 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 233 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 234 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 235 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 236 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 237 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 238 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 239 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 240 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 241 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 242 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 243 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 244 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 245 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 246 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 247 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 248 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 249 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 250 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 251 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 252 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 253 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 254 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 255 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 256 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 257 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 258 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 259 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 260 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 261 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 262 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 263 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 264 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 265 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 266 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 267 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 268 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 269 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 270 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 271 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 272 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 273 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 274 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 275 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 276 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 277 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 278 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 279 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 280 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 281 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 282 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 283 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 284 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 285 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 286 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 287 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 288 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 289 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 290 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 291 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 292 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 293 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 294 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 295 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 296 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 297 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 298 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 299 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 300 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 301 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 302 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 303 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 304 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 305 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 306 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 307 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 308 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 309 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 310 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 311 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 312 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][noflash_bs1_seq4096] step 24/40 (60.0%)  wall=  34.3s  tps≈  716.6
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 313 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 314 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 315 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 316 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 317 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 318 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 319 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 320 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 321 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 322 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 323 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 324 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 325 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 326 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 327 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 328 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 329 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 330 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 331 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 332 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 333 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 334 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 335 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 336 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 337 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 338 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 339 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 340 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 341 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 342 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 343 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 344 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 345 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 346 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 347 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 348 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 349 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 350 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 351 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 352 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 353 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 354 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 355 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 356 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 357 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 358 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 359 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 360 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 361 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 362 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 363 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 364 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 365 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 366 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 367 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 368 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 369 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 370 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 371 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 372 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 373 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 374 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 375 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 376 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 377 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 378 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 379 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 380 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 381 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 382 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 383 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 384 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 385 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 386 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 387 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 388 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 389 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 390 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 391 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 392 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 393 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 394 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 395 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 396 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][noflash_bs1_seq4096] step 31/40 (77.5%)  wall=  44.4s  tps≈  715.0
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 397 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 398 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 399 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 400 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 401 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 402 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 403 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 404 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 405 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 406 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 407 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 408 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 409 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 410 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 411 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 412 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 413 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 414 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 415 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 416 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 417 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 418 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 419 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 420 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
