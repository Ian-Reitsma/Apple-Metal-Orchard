>> QUICK-CHECK mode: bs=4 seq=256 steps=40 (≈15-min run)
[orchard][flashpatch] FlashAttention monkeypatch ENABLED (GPT2Attention.forward, log=True, detail=False)
MPS available: True MPS built: True
[orchard] FlashAttention loaded (SHA e1b8e65a…)
[orchard][flashpatch] --- FlashAttention Patch Context ---
  PATCH_ENABLED: True
  FLASHATTN_LOG_KERNEL: True
  FLASHATTN_LOG_DETAIL: False
  torch version: 2.7.1
  Model config (first layer): GPT2Config {
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "torch_dtype": "float32",
  "transformers_version": "4.53.0",
  "use_cache": true,
  "vocab_size": 50257
}

  Example Q shape: torch.Size([4, 12, 256, 64]), dtype: torch.bfloat16, device: mps:0
  ENV: USE_FLASH_ATTN=1, PYTHONHASHSEED=None
-------------------------------------------------------------
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 1 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 2 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 3 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 4 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 5 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 6 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 7 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 8 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 9 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 10 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 11 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 12 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 13 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 14 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 15 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 16 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 17 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 18 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 19 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 20 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 21 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 22 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 23 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 24 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 25 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 26 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 27 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 28 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 29 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 30 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 31 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 32 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 33 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 34 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 35 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 36 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flash_bs1_seq4096] step 1/40 ( 2.5%)  wall=   1.9s  tps≈  550.5
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 37 (layer=0): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 38 (layer=1): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 39 (layer=2): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 40 (layer=3): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 41 (layer=4): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 42 (layer=5): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 43 (layer=6): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 44 (layer=7): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 45 (layer=8): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 46 (layer=9): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 47 (layer=10): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
[orchard][flashpatch] ERROR: FlashAttention kernel failed on call 48 (layer=11): '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
---- Kernel Input Shapes ----
  Q: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  K: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
  V: torch.Size([4, 12, 256, 64]), dtype=torch.bfloat16, device=mps:0
---- Kernel Exception Trace ----
Traceback (most recent call last):
  File "/Users/ianreitsma/projects/orchard/benchmarks/orchard_patch_flash.py", line 94, in flashattention_forward
    attn_output = torch.ops.flash_attn_mps._flash_attn_fwd(
  File "/Users/ianreitsma/projects/orchard/orchard-env/lib/python3.9/site-packages/torch/_ops.py", line 1267, in __getattr__
    raise AttributeError(
AttributeError: '_OpNamespace' 'flash_attn_mps' object has no attribute '_flash_attn_fwd'
[orchard][flashpatch] Fallback to original GPT2Attention.forward
